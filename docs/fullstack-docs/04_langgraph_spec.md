# ğŸ¤– SmartOCR Pro - LangGraph AI ëª…ì„¸ì„œ

---

## ğŸ¯ LangGraph ì‹œìŠ¤í…œ ê°œìš”

LangGraphëŠ” SmartOCR Proì˜ í•µì‹¬ AI ì—”ì§„ìœ¼ë¡œ, PDFì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ê³ í’ˆì§ˆë¡œ ë³´ì •í•˜ê³  ë‹¤ì–‘í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

### ğŸ—ï¸ ì•„í‚¤í…ì²˜ êµ¬ì¡°
```
Frontend â†â†’ Backend â†â†’ Shared Storage â†â†’ LangGraph API â†â†’ OpenAI GPT-4
             â†“                â†‘                      â†â†’ Translation APIs
         WebSocket      Metadata Files              â†â†’ Text Processing Tools
       (ì‹¤ì‹œê°„ ì§„í–‰ë¥ )   (ì§„í–‰ ìƒíƒœ ì¶”ì )
```

### ğŸ“ íŒŒì¼ ê¸°ë°˜ ì²˜ë¦¬ íë¦„
1. **Backend**: PDFë¥¼ ê³µìœ  ìŠ¤í† ë¦¬ì§€ì— ì €ì¥
2. **LangGraph**: íŒŒì¼ ê²½ë¡œì™€ ë©”íƒ€ë°ì´í„°ë§Œ ìˆ˜ì‹ 
3. **Processing**: í…ìŠ¤íŠ¸ ì²­í¬ë³„ë¡œ AI ì²˜ë¦¬
4. **Tracking**: metadata.jsonìœ¼ë¡œ ì§„í–‰ ìƒíƒœ ì¶”ì 
5. **Frontend**: WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

---

## ğŸ”„ LangGraph ì›Œí¬í”Œë¡œìš° ì„¤ê³„

### ğŸ“Š Main OCR Processing Graph

```python
# ì£¼ìš” ì²˜ë¦¬ ë‹¨ê³„
workflow = StateGraph(OCRState)

# ë…¸ë“œ ì •ì˜
workflow.add_node("extract_text", extract_pdf_text)
workflow.add_node("chunk_text", chunk_large_text)
workflow.add_node("analyze_quality", analyze_text_quality) 
workflow.add_node("correct_chunks", correct_text_chunks)
workflow.add_node("validate_quality", validate_correction_quality)
workflow.add_node("translate_text", translate_if_needed)
workflow.add_node("finalize_output", merge_and_format)

# ì—£ì§€ ì •ì˜ (ì¡°ê±´ë¶€ ë¼ìš°íŒ…)
workflow.add_conditional_edges(
    "analyze_quality",
    decide_processing_strategy,
    {
        "high_quality": "finalize_output",      # í’ˆì§ˆ ì¢‹ìŒ â†’ ë°”ë¡œ ì™„ë£Œ
        "medium_quality": "correct_chunks",     # ë³´í†µ â†’ AI ë³´ì •
        "low_quality": "correct_chunks",        # ë‚˜ì¨ â†’ AI ë³´ì •
        "too_large": "chunk_text"               # ë„ˆë¬´ í¼ â†’ ë¶„í•  ì²˜ë¦¬
    }
)

workflow.add_conditional_edges(
    "validate_quality",
    decide_next_action,
    {
        "translation_needed": "translate_text",
        "output_ready": "finalize_output",
        "retry_correction": "correct_chunks"
    }
)
```

### ğŸ§  OCR State ì •ì˜
```python
from typing import TypedDict, List, Optional

class OCRState(TypedDict):
    # ğŸ”‘ ë©”íƒ€ë°ì´í„° (HTTPë¡œ ì „ì†¡)
    process_id: str
    file_path: str
    user_options: dict
    
    # ğŸ“Š ì²˜ë¦¬ ìƒíƒœ
    current_step: str
    progress: int
    quality_score: Optional[float]
    chunk_count: int
    completed_chunks: int
    
    # ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­
    confidence_score: Optional[float]
    error_count: Optional[int]
    processing_time: Optional[float]
    estimated_remaining: Optional[int]
    
    # ğŸš¨ ì—ëŸ¬ ë° ë¡œê·¸
    errors: List[str]
    logs: List[str]
    
    # ğŸ¯ ì²˜ë¦¬ ì˜µì…˜
    enable_translation: bool
    target_language: Optional[str]
    quality_level: str  # 'low', 'medium', 'high'
```

---

## ğŸ”§ LangGraph ë…¸ë“œ ìƒì„¸ ì •ì˜

### 1ï¸âƒ£ extract_pdf_text ë…¸ë“œ
```python
def extract_pdf_text(state: OCRState) -> OCRState:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    
    # pdftotext ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
    raw_text = extract_with_pdftotext(state["file_path"])
    
    return {
        **state,
        "raw_text": raw_text,
        "current_step": "extraction_complete",
        "progress": 20
    }
```

### 2ï¸âƒ£ analyze_quality ë…¸ë“œ
```python
def analyze_quality(state: OCRState) -> OCRState:
    """í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„"""
    
    prompt = """
    Please evaluate the quality of the following text on a scale of 0-100.
    Evaluation criteria:
    - Grammatical accuracy
    - Completeness of sentence structure  
    - Typos and special character errors
    - Clarity of meaning
    
    Text: {text}
    
    Please return only the score as a number.
    """
    
    quality_score = llm_call(prompt, text=state["raw_text"])
    
    return {
        **state,
        "quality_score": float(quality_score),
        "current_step": "quality_analyzed", 
        "progress": 40
    }
```

### 3ï¸âƒ£ correct_errors ë…¸ë“œ
```python
def correct_errors(state: OCRState) -> OCRState:
    """AI ê¸°ë°˜ í…ìŠ¤íŠ¸ ì˜¤ë¥˜ ìˆ˜ì •"""
    
    correction_prompt = """
    The following is text extracted from a PDF. Please correct these errors:

    1. Incorrect character recognition due to OCR extraction errors
    2. Missing or excessive spaces between words
    3. Punctuation errors
    4. Word separation due to line break errors
    5. Special character misrecognition
    
    Please correct to natural language while preserving the original meaning.
    Detect the language automatically and respond in the same language.
    
    Original text:
    {raw_text}
    
    Please return only the corrected text.
    """
    
    corrected_text = llm_call(
        correction_prompt, 
        raw_text=state["raw_text"]
    )
    
    return {
        **state,
        "corrected_text": corrected_text,
        "current_step": "errors_corrected",
        "progress": 70
    }
```

### 4ï¸âƒ£ format_output ë…¸ë“œ
```python
def format_output(state: OCRState) -> OCRState:
    """ì¶œë ¥ í˜•ì‹ í¬ë§·íŒ…"""
    
    text_to_format = state.get("corrected_text") or state["raw_text"]
    
    # ì‚¬ìš©ì ì˜µì…˜ì— ë”°ë¥¸ í¬ë§·íŒ…
    options = state["user_options"]
    
    if options.get("preserve_structure"):
        formatted_text = preserve_document_structure(text_to_format)
    else:
        formatted_text = clean_text_format(text_to_format)
    
    return {
        **state,
        "formatted_text": formatted_text,
        "current_step": "formatting_complete",
        "progress": 80
    }
```

### 5ï¸âƒ£ translate_text ë…¸ë“œ (ì¡°ê±´ë¶€)
```python
def translate_text(state: OCRState) -> OCRState:
    """í…ìŠ¤íŠ¸ ë²ˆì—­ (ì„ íƒì‚¬í•­)"""
    
    if not state["user_options"].get("enable_translation"):
        return state
    
    target_language = state["user_options"]["target_language"]
    source_text = state["formatted_text"]
    
    translation_prompt = f"""
    Please translate the following text to {target_language} naturally.
    Provide professional and accurate translation.
    
    Text: {source_text}
    """
    
    translated_text = llm_call(translation_prompt)
    
    return {
        **state,
        "translated_text": translated_text,
        "current_step": "translation_complete",
        "progress": 90
    }
```

### 6ï¸âƒ£ generate_outputs ë…¸ë“œ
```python
def generate_outputs(state: OCRState) -> OCRState:
    """ìµœì¢… ì¶œë ¥ íŒŒì¼ ìƒì„±"""
    
    outputs = []
    requested_formats = state["user_options"]["output_formats"]
    
    # í…ìŠ¤íŠ¸ ì¶œë ¥
    if "text" in requested_formats:
        text_output = {
            "type": "text",
            "content": state["formatted_text"],
            "filename": f"{state['process_id']}_result.txt"
        }
        outputs.append(text_output)
    
    # PDF ì¶œë ¥
    if "pdf" in requested_formats:
        pdf_path = generate_pdf_from_text(
            state["formatted_text"], 
            state["process_id"]
        )
        pdf_output = {
            "type": "pdf", 
            "file_path": pdf_path,
            "filename": f"{state['process_id']}_result.pdf"
        }
        outputs.append(pdf_output)
    
    # ë²ˆì—­ë³¸ ì¶œë ¥
    if "translation" in requested_formats and state.get("translated_text"):
        translation_output = {
            "type": "translation",
            "content": state["translated_text"], 
            "language": state["user_options"]["target_language"],
            "filename": f"{state['process_id']}_translation.txt"
        }
        outputs.append(translation_output)
    
    return {
        **state,
        "outputs": outputs,
        "current_step": "completed",
        "progress": 100
    }
```

---

## ğŸ”€ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë¡œì§

### í’ˆì§ˆ ê¸°ë°˜ ì²˜ë¦¬ ë¶„ê¸°
```python
def decide_correction_level(state: OCRState) -> str:
    """í…ìŠ¤íŠ¸ í’ˆì§ˆì— ë”°ë¥¸ ì²˜ë¦¬ ê²½ë¡œ ê²°ì •"""
    
    quality_score = state["quality_score"]
    
    if quality_score >= 85:
        return "high_quality"  # ë°”ë¡œ í¬ë§·íŒ…
    elif quality_score >= 60:
        return "medium_quality"  # ê¸°ë³¸ ìˆ˜ì •
    else:
        return "low_quality"  # ê°•í™”ëœ ìˆ˜ì •
```

### ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
```python
def handle_processing_error(state: OCRState) -> str:
    """ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ ì²˜ë¦¬"""
    
    error_count = len(state.get("errors", []))
    
    if error_count < 3:
        return "retry"
    else:
        return "failed"
```

---

## ğŸŒ LangGraph API ì—”ë“œí¬ì¸íŠ¸

### ğŸ“¡ OCR ì²˜ë¦¬ ì‹œì‘
```python
@app.post("/api/langgraph/process")
async def start_ocr_process(request: OCRRequest):
    """OCR ì²˜ë¦¬ ì‹œì‘"""
    
    initial_state = {
        "file_path": request.file_path,
        "process_id": request.process_id,
        "user_options": request.options,
        "current_step": "initialized",
        "progress": 0,
        "errors": []
    }
    
    # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = await workflow.ainvoke(initial_state)
    
    return {
        "success": True,
        "process_id": request.process_id,
        "estimated_time": calculate_estimated_time(request.options)
    }
```

### ğŸ“Š ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ
```python
@app.get("/api/langgraph/status/{process_id}")
async def get_process_status(process_id: str):
    """ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ"""
    
    # Redisë‚˜ ë©”ëª¨ë¦¬ì—ì„œ í˜„ì¬ ìƒíƒœ ì¡°íšŒ
    state = get_process_state(process_id)
    
    return {
        "process_id": process_id,
        "status": state.get("current_step", "unknown"),
        "progress": state.get("progress", 0),
        "estimated_time_remaining": calculate_remaining_time(state)
    }
```

### ğŸ“¥ ì²˜ë¦¬ ê²°ê³¼ ì¡°íšŒ
```python
@app.get("/api/langgraph/result/{process_id}")
async def get_process_result(process_id: str):
    """ì²˜ë¦¬ ê²°ê³¼ ì¡°íšŒ"""
    
    state = get_final_state(process_id)
    
    if state.get("current_step") != "completed":
        raise HTTPException(404, "Processing not completed")
    
    return {
        "process_id": process_id,
        "outputs": state["outputs"],
        "processing_time": state.get("processing_time"),
        "confidence_score": state.get("confidence_score")
    }
```

---

## âš™ï¸ LangGraph ì„¤ì • ë° í™˜ê²½

### ğŸ¤– LLM ëª¨ë¸ ì„¤ì •
```python
from langchain_openai import ChatOpenAI

# ì£¼ìš” ì²˜ë¦¬ìš© GPT-4
primary_llm = ChatOpenAI(
    model="gpt-4-turbo-preview",
    temperature=0.1,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ê²Œ ì„¤ì •
    max_tokens=4000,
    timeout=60
)

# ë¹ ë¥¸ ì²˜ë¦¬ìš© GPT-3.5
fast_llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0.1,
    max_tokens=2000,
    timeout=30
)
```

### ğŸ”§ ì²˜ë¦¬ ì˜µì…˜ ìŠ¤í‚¤ë§ˆ
```python
class OCROptions(BaseModel):
    """OCR processing options"""
    
    language: str = "auto"  # Source language (auto-detect)
    output_formats: List[str] = ["text"]  # Output formats
    preserve_structure: bool = True  # Preserve document structure
    correction_level: str = "auto"  # Correction intensity (auto/light/heavy)
    
    # Translation options
    enable_translation: bool = False
    target_language: str = "en"  # Target language for translation
    
    # Advanced options
    remove_headers_footers: bool = False
    merge_paragraphs: bool = False
    custom_instructions: Optional[str] = None
    
    # Supported languages
    supported_languages: List[str] = [
        "en", "es", "fr", "de", "ja", "zh", "ko", "pt", "it", "ru"
    ]
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### ğŸš€ ì²˜ë¦¬ ì†ë„ ìµœì í™”
- **ë³‘ë ¬ ì²˜ë¦¬**: ë…ë¦½ì ì¸ ë…¸ë“œë“¤ì˜ ë™ì‹œ ì‹¤í–‰
- **ëª¨ë¸ ìºì‹±**: ìì£¼ ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ê²°ê³¼ ìºì‹±
- **ì²­í¬ ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ì˜ ë¶„í•  ì²˜ë¦¬

### ğŸ“ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
```python
# ì²˜ë¦¬ ì‹œê°„ ë©”íŠ¸ë¦­
processing_time_histogram = Histogram(
    'ocr_processing_duration_seconds',
    'OCR processing duration'
)

# í’ˆì§ˆ ì ìˆ˜ ë©”íŠ¸ë¦­  
quality_score_gauge = Gauge(
    'ocr_quality_score',
    'OCR output quality score'
)

# ì—ëŸ¬ìœ¨ ë©”íŠ¸ë¦­
error_rate_counter = Counter(
    'ocr_processing_errors_total',
    'Total OCR processing errors'
)
```

### ğŸ” ë¡œê¹… ë° ë””ë²„ê¹…
- **êµ¬ì¡°í™”ëœ ë¡œê¹…**: JSON í˜•íƒœì˜ ìƒì„¸ ë¡œê·¸
- **ë‹¨ê³„ë³„ ì¶”ì **: ê° ë…¸ë“œì˜ ì…ì¶œë ¥ ê¸°ë¡
- **ì—ëŸ¬ ì¶”ì **: ì‹¤íŒ¨ ì§€ì ê³¼ ì›ì¸ ë¶„ì„

---

## ğŸ” ë³´ì•ˆ ë° ë°ì´í„° ì²˜ë¦¬

### ğŸ›¡ï¸ ë³´ì•ˆ ì¡°ì¹˜
- **API í‚¤ ê´€ë¦¬**: í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•œ ì•ˆì „í•œ í‚¤ ê´€ë¦¬
- **ìš”ì²­ ê²€ì¦**: ì…ë ¥ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
- **ê²°ê³¼ ì•”í˜¸í™”**: ë¯¼ê°í•œ ì²˜ë¦¬ ê²°ê³¼ ì•”í˜¸í™” ì €ì¥

### ğŸ—‘ï¸ ë°ì´í„° ì •ë¦¬ ì •ì±…
- **ì„ì‹œ íŒŒì¼**: ì²˜ë¦¬ ì™„ë£Œ í›„ 24ì‹œê°„ ë‚´ ì‚­ì œ
- **ì²˜ë¦¬ ìƒíƒœ**: 7ì¼ í›„ ìë™ ì •ë¦¬
- **ë¡œê·¸ ë°ì´í„°**: 30ì¼ ë³´ê´€ í›„ ì•„ì¹´ì´ë¸Œ 